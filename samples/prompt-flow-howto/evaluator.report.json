{
  "prompt": "---\nname: basic evaluate \ndescription: basic evaluator for QA scenario\nsource: PromptFlow How-to Guides (slightly modified)\nurl: https://github.com/microsoft/promptflow/blob/main/examples/prompty/eval-basic/eval.prompty\ninputs: \n  question:\n    type: string\n  answer:\n    type: string\n  statement:\n    type: string\noutputs:\n  score:\n    type: string\n  explanation:\n    type: string\n---\nsystem:\nYou are an AI assistant. \nYou task is to evaluate a score for the answer based on the ground_truth and original question.\nThis score value should always be an integer between 1 and 5. So the score produced should be 1 or 2 or 3 or 4 or 5.\nThe output should be valid JSON.\n\n**Example**\nquestion: \"What is the capital of France?\"\nanswer: \"Paris\"\nground_truth: \"Paris\"\noutput:\n{\"score\": \"5\", \"explanation\":\"paris is the capital of France\"}\n\nuser:\nquestion: {{question}}\nanswer: {{answer}}\nstatement: {{statement}}\noutput:\n",
  "inputSpec": "The input must include a \"question\" string that represents an inquiry or prompt.  \nThe input must include an \"answer\" string that represents the response given to the question.  \nThe input must include a \"statement\" string that provides additional context or information related to the question and answer.",
  "rules": [
    "The output must be in valid JSON format.",
    "The JSON output must contain a key named \"score\".",
    "The value for the \"score\" key must be an integer between 1 and 5, inclusive.",
    "The JSON output must contain a key named \"explanation\".",
    "The value for the \"explanation\" key must be a string that provides a rationale for the assigned score."
  ],
  "inverseRules": [
    "Output must not be in valid JSON format.",
    "The JSON output must not contain a key named \"score\".",
    "The value for the \"score\" key must not be an integer between 1 and 5, inclusive.",
    "The JSON output must not contain a key named \"explanation\".",
    "The value for the \"explanation\" key must not be a string that provides a rationale for the assigned score."
  ],
  "baseLineTests": [
    "question: \"What is the capital of Spain?\"\nanswer: \"Madrid\"\nground_truth: \"Madrid\"\noutput:",
    "question: \"Who wrote 'Hamlet'?\"\nanswer: \"Shakespeare\"\nground_truth: \"William Shakespeare\"\noutput:",
    "question: \"What is the largest planet in our solar system?\"\nanswer: \"Jupiter\"\nground_truth: \"Jupiter\"\noutput:",
    "question: \"What is the boiling point of water?\"\nanswer: \"100 degrees Celsius\"\nground_truth: \"100Â°C\"\noutput:",
    "question: \"What year did the Titanic sink?\"\nanswer: \"1912\"\nground_truth: \"1912\"\noutput:",
    "question: \"Who painted the Mona Lisa?\"\nanswer: \"Leonardo da Vinci\"\nground_truth: \"Leonardo da Vinci\"\noutput:",
    "question: \"What is the chemical symbol for water?\"\nanswer: \"H2O\"\nground_truth: \"H2O\"\noutput:",
    "question: \"What is the primary language spoken in Brazil?\"\nanswer: \"Portuguese\"\nground_truth: \"Portuguese\"\noutput:",
    "question: \"What is the square root of 64?\"\nanswer: \"8\"\nground_truth: \"8\"\noutput:",
    "question: \"Who discovered penicillin?\"\nanswer: \"Alexander Fleming\"\nground_truth: \"Alexander Fleming\"\noutput:"
  ],
  "tests": [
    {
      "rule": "The output must be in valid JSON format.",
      "input": "question: 'What is the largest planet in our solar system?' answer: 'Jupiter' statement: 'Jupiter is known as the largest planet and is a gas giant.'",
      "expected": "{\"score\": \"5\", \"explanation\": \"Jupiter is correctly identified as the largest planet.\"}",
      "reasoning": "Tests valid JSON format where 'score' key is present, ensuring it follows the input specification and JSON requirements."
    },
    {
      "rule": "The output must be in valid JSON format.",
      "input": "question: 'What is the boiling point of water?' answer: '100 degrees Celsius' statement: 'Water boils at this temperature at sea level.'",
      "expected": "{\"score\": \"5\", \"explanation\": \"The boiling point of water is correctly given as 100 degrees Celsius.\"}",
      "reasoning": "Confirms presence of 'explanation' key with valid content, while adhering to input specification."
    },
    {
      "rule": "The output must be in valid JSON format.",
      "input": "question: 'Who wrote Macbeth?' answer: 'William Shakespeare' statement: 'Macbeth is a famous tragedy written by this author.'",
      "expected": "{\"score\": \"5\", \"explanation\": \"William Shakespeare is correctly identified as the author.\"}",
      "reasoning": "Ensures JSON structure is valid and explanation is informative, satisfying input specification and JSON rules."
    },
    {
      "rule": "The JSON output must contain a key named \"score\".",
      "input": "question: 'What is the smallest ocean in the world?' answer: 'Arctic Ocean' statement: 'It is located in the Northern Hemisphere and is the smallest by surface area.'",
      "expected": "{\"score\": \"5\", \"explanation\": \"Arctic Ocean is correctly identified as the smallest ocean.\"}",
      "reasoning": "Tests presence of 'score' key and validity of explanation, meeting input and JSON format specifications."
    },
    {
      "rule": "The JSON output must contain a key named \"score\".",
      "input": "question: 'What is the main language spoken in Brazil?' answer: 'Portuguese' statement: 'This language is widely spoken throughout the country.'",
      "expected": "{\"score\": \"5\", \"explanation\": \"Portuguese is correctly identified as the main language spoken in Brazil.\"}",
      "reasoning": "Tests JSON output for correct key presence and value, ensuring input specification adherence."
    },
    {
      "rule": "The JSON output must contain a key named \"score\".",
      "input": "question: 'Which element has the atomic number 1?' answer: 'Hydrogen' statement: 'It is the lightest and most abundant element in the universe.'",
      "expected": "{\"score\": \"5\", \"explanation\": \"Hydrogen is correctly identified with atomic number 1.\"}",
      "reasoning": "Verifies JSON output contains 'explanation', complying with input and JSON requirements."
    },
    {
      "rule": "The value for the \"score\" key must be an integer between 1 and 5, inclusive.",
      "input": "question: 'What is the primary color of the sky on a clear day?' answer: 'Blue' statement: 'This color results from scattering of sunlight.'",
      "expected": "{\"score\": \"5\", \"explanation\": \"Blue is correctly identified as the primary color of the sky.\"}",
      "reasoning": "Confirms 'score' value is an integer between 1 and 5, ensuring compliance with numeric range rule."
    },
    {
      "rule": "The value for the \"score\" key must be an integer between 1 and 5, inclusive.",
      "input": "question: 'Which continent is Australia on?' answer: 'Australia' statement: 'It is both a country and a continent.'",
      "expected": "{\"score\": \"5\", \"explanation\": \"Australia is correctly identified as both a country and a continent.\"}",
      "reasoning": "Ensures 'score' is an integer and explanation is valid, adhering to input specification."
    },
    {
      "rule": "The value for the \"score\" key must be an integer between 1 and 5, inclusive.",
      "input": "question: 'What is 2+2?' answer: '4' statement: 'This is a basic arithmetic operation.'",
      "expected": "{\"score\": \"5\", \"explanation\": \"2+2 is correctly calculated as 4.\"}",
      "reasoning": "Tests integer 'score' requirement, ensuring proper JSON format and input specification compliance."
    }
  ]
}