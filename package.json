{
  "devDependencies": {
    "prettier": "^3.3.3"
  },
  "scripts": {
    "serve": "cd app && streamlit run main.py",
    "genai": "npx --yes genaiscript run",
    "gcm": "npx --yes genaiscript run gcm",
    "prd": "npx --yes genaiscript run prd -prd",
    "build": "npx --yes genaiscript scripts compile",
    "promptpex": "npx --yes genaiscript run promptpex",
    "run_tests:ollama": "npx --yes genaiscript run promptpex_run_tests --vars \"models=ollama:phi3.5;ollama:qwen2.5:3b;ollama:llama3.2:3b;ollama:llama3.1:8b;ollama:gemma2:9b;ollama:mistral-nemo\" --vars concurrency=1 --model ollama:phi3.5",
    "run_tests:ollama-12b": "npx --yes genaiscript run promptpex_run_tests --vars \"models=ollama:mistral-nemo;ollama:mistral-small:22b;ollama:deepseek-coder-v2:16b\" --vars concurrency=1 --model ollama:phi3.5",
    "run_tests:azure_serverless": "npx --yes genaiscript run promptpex_run_tests --vars \"models=azure_serverless:gpt-4o-mini\" --vars concurrency=1 --model azure_serverless:gpt_4o",
    "run_tests:github": "npx --yes genaiscript run promptpex_run_tests --vars \"models=github:gpt-4o-mini\" --vars concurrency=3 --model github:gpt_4o",
    "coverage": "npx --yes genaiscript run promptpex_coverage",
    "promptpex:paper": "npx --yes genaiscript run promptpex \"samples/**/*.prompty\" --vars \"models=azure_serverless:gpt-4o-mini;ollama:qwen2.5:3b;gemma2:9b --vars concurrency=1 --vars \"out=paper/evals/v0\""
  }
}
